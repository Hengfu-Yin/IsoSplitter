#!/usr/bin/env python3

import subprocess
import os
import sys
import re
import multiprocessing
import argparse
import distutils.spawn
import time

#The first time to screen the data produced by sim4, and the output file is Sim4_align_out.txt
def FirstDataProcess(listArgs):
	#Open the result file generated by sim4
	with open(listArgs[3]+"/"+listArgs[0],'r') as file_obj :
		r = file_obj.readline()
		#Find the first line starting with seq1
		while not re.match('seq1', r):
			r = file_obj.readline()
			if not r:
				break
		#Go through each line of the file to screen data
		while r:
			count = 0 #count the number of '%'
			flag = 1  #define whether to write to a file, 1 means write
			r = r[:re.search("=",r).start()+2] + r[re.search('/',r).start()+1:]
			ss = r  #ss saves the content to be written
			r = file_obj.readline()
			r = r[:re.search("=",r).start()+2] + r[re.search('\(',r).start():]
			ss = ss + r
			r = file_obj.readline()
			while not re.match('seq1', r):
				if not r.isspace():
					ss = ss + r
					matchObject = re.search('%',r)
					#Require that identity of each row be greater than or equal to the specified identity, and count the row.
					#Require that each matched fragment be greater than or equal to the specified length
					if matchObject:
						number = matchObject.start()
						if flag == 1 and (int(r[number-2:number]) >= listArgs[1] or int(r[number-2:number]) == 0):
							count = count + 1
						else:
							flag = 0
						if flag == 1:
							num1,num2 = r[0:re.search('\(',r).start()-2].split('-')
							if (int(num2) - int(num1) + 1 < int(listArgs[2])):
								flag = 0
				r = file_obj.readline()
				if not r:
					break
			if count >= 2 and flag == 1:
				with open(listArgs[3]+"/Sim4_align_out.txt",'a') as obj:
					obj.write(ss+"\n")
	#remove the result file generated by sim4
	subprocess.run('rm -rf '+listArgs[3]+"/"+listArgs[0],shell=True)

#Principal function of process processing
def ProcessDo(firstFileName,secondFileName,s,seqfile,identity,length,dirName):
	with open(dirName+"/"+firstFileName,'w') as obj:
		obj.write(s)
	#call sim4
	subprocess.run('sim4 '+dirName+"/"+firstFileName+' '+seqfile+' W=15'+' > '+dirName+"/"+secondFileName,shell=True)
	#remove 'eachSeqence' file
	subprocess.run('rm -rf '+dirName+"/"+firstFileName,shell=True)
	#parameters of 'FirstDataProcess' function
	listArgs = [secondFileName,identity,length,dirName]
	return listArgs

#Call sim4 for global alignment	
def CallSim4(seqfile,identity,length,processes,dirName):
	#Create a process pool
	pool = multiprocessing.Pool(processes)
	#Open the file you put in the command line.
	with open(seqfile,'r') as seq_obj :
		r = seq_obj.readline()
		while not re.match('>', r):
			r = seq_obj.readline()
			if not r:
				break
		#Go through each seqence, use the seqence name to create a file and contain the seqence.
		#Use the 'eachSeqence' file and whole deqence file as the sim4's input files.
		while r:
			#name = r.split(maxsplit=1)[0][1:].replace(r"/",r"_")
			name = r.split(maxsplit=1)[0][1:]
			if re.search("/",name):
				print("error: character '/' can not in the name of seqence!")
				sys.exit()
			firstFileName = name+r".fasta"
			secondFileName = name+r".txt"
			s = r
			r = seq_obj.readline()
			while not re.match('>', r):
				s = s + r				
				r = seq_obj.readline()
				if not r:
					break
			#process non-blocking call 'ProcessDo' function, and give the return value to the 'FirstDataProcess' function to filter.
			pool.apply_async(ProcessDo, args=(firstFileName,secondFileName,s,seqfile,identity,length,dirName,),callback=FirstDataProcess)
	pool.close()
	pool.join()

#Define command line parameters
def CommandLineArgs(thread):
	des="A de novo identification tool of alternative splicing sites using long-reads transcriptome without a reference genome."
	useage="IsoSplittingAnchor [options] longReadsFile"
	parser=argparse.ArgumentParser(usage=useage,description=des,formatter_class=argparse.ArgumentDefaultsHelpFormatter)
	parser.add_argument('longReadsFile',help="the transcripts sequence file in fasta format",type=lambda x: CheckSeqfile(parser,x))
	parser.add_argument('-v','--version', action='version', version='IsoSplittingAnchor.py 1.0')
	parser.add_argument('-i',dest='identity',metavar='<integer>',help='the minimum identity(0-100)',type=int,default=95)
	parser.add_argument('-L',dest='length',metavar='<integer+bp>',help='the minimum length of each matched fragment(>14bp)',default='30bp')
	parser.add_argument('-t',dest='thread',metavar='<integer>',help='the number of threads(default is use all available threads)',type=int,default=thread)
	args = parser.parse_args()
	return args

#check the input file whether exit
def CheckSeqfile(parser,fname):
	if not os.path.isfile(fname):
		parser.error("The file "+fname+" is not found\n")
	else:
		return fname

#The second time to screen the data produced by 'FirstDataProcess' function, and the output files are Breakpoint_out.txt and GeneCluster.txt
def SecondDataProcess(dirName):
	#open file Sim4_align_out.txt
	with open(dirName+"/Sim4_align_out.txt",'r') as file_obj :
		r = file_obj.readline()
		while not re.match('seq1', r):
			r = file_obj.readline()
			if not r:
				break
		number = 0 #count the number of homologous sequence
		Dict = {} #save breakpoints and number of occurrences
		ss = "" #save Cluster (sequence name)
		while r:
			s = ""
			first = r
			second = file_obj.readline()
			r = file_obj.readline()
			counter = 0 #count the number of '%'
			writer = 0 #define whether to write to a file, 1 means write
			List = [] #save the points of every seqence
			while not re.match('seq1', r):
				if not r.isspace():
					s = s + r
					matchObject = re.search('%',r)
					#save every point to List
					if matchObject:
						counter = counter + 1
						str1 = r[0:re.search('\(',r).start()-2]
						num1,num2 = str1.split('-')
						List.append(int(num1))
						List.append(int(num2))
				r = file_obj.readline()
				if not r:
					break	
			#the situation of % appear twice	
			if counter == 2 :	
				gap = List[2] - List[1]
				if gap == 1:				
					writer = 1	
			#the situation of % appear >=3										
			else:
				i = 1
				while (i + 1 < len(List)):
					if(List[i+1] - List[i] == 1):
						i = i + 2
					else:
						break
				if i + 1 == len(List):
					writer = 1
			#under the situation of can write, count breakpoints and Cluster.
			if(writer == 1):
				number = number + 1
				if number == 1:
					ss = ss + first.split()[2][:-7]
				ss = ss+"  "+second.split()[2][1:-2]
				i = 1
				while(i + 1 < len(List)):
					if i % 2 != 0:
						key = List[i]					
						if  key in Dict:
							Dict[key] = Dict[key] + 1
						else:
							Dict[key] = 1
					i = i + 1
			if(first == r and writer == 1):
				number = number + 1					
			elif(first != r and number != 0):
				#write to Breakpoint_out.txt
				with open(dirName+"/Breakpoint_out.txt",'a') as obj:
					obj.write("seq = "+first.split()[2][:-7]+"\n")
					obj.write(str(int((number+1)/2)))
					obj.write("   "+str(Dict))
					obj.write("\n")		
				Dict.clear()
				#write to GeneCluster.txt
				with open(dirName+"/GeneCluster.txt",'a') as obj:
					obj.write(ss+"\n")
					ss = ""
				number = 0

'''
#Merge the records in GeneClusterTemp.txt: the same and be included
def ThirdDataProcess(dirName):
	#save GeneClusterTemp.txt to dictAll({first of the group: [group]}...) and save 'first of the group' to dictKey
	with open(dirName+"/GeneClusterTemp.txt",'r') as obj:
		dictAll=dict()
		dictKey=[]
		for i in obj:
			listI=i.split()
			dictAll[listI[0]]=listI
			dictKey.append(listI[0])
	#delete the same and be included from dictKey
	i=0
	while(i<len(dictKey)):
		listI=dictAll[dictKey[i]]
		j=0
		while j<len(dictKey):
			if i != j:
				listJ = dictAll[dictKey[j]]
				count=0
				for k in listI:
					if k not in listJ:
						break
					else:
						count=count+1
				if count==len(listI) and count!=len(listJ):
					dictKey.remove(dictKey[i])
					i=i-1
					break
				elif count==len(listI) and count==len(listJ):
					dictKey.remove(dictKey[j])
					i=i-1
					break
				else:
					j=j+1
			else:
				j=j+1
		i=i+1
	#write the remaining merged groups to GeneCluster.txt
	for i in dictKey:
		r=dictAll[i][0]
		for j in dictAll[i][1:]:
			r=r+"  "+j
		with open(dirName+"/GeneCluster.txt",'a') as obj:
			obj.write(r+"\n")
'''

#Check your environment whether installed sim4 and sim4 is in PATH.
def CheckSim4():
	ret = distutils.spawn.find_executable("sim4")
	#Print the error message and exit the program
	if not ret:
		print("error:The sim4 is required but not installed or not in the PATH!")
		sys.exit()

#The main process of script
def Main():
	#check dependence sim4.
	CheckSim4()
	#command-line argument parsing.
	thread = multiprocessing.cpu_count()
	args = CommandLineArgs(thread)
	if args.identity > 100 or args.identity <= 0:
		print("error:The identity should between 1 and 100 !")
		sys.exit()
	length = int(args.length[:-2])
	if length < 15:
		print("error:The length should greater 14bp !")
		sys.exit()
	if args.thread < 1 or args.thread > thread:
		print("error:The threads number should between 1 and "+str(thread))
		sys.exit()
	#Find the directory where the script is running and create the output directory (Fout[time]) under that directory
	exec_dir = os.path.dirname(os.path.realpath(__file__))
	dirName="Fout"+str(int(time.time()))
	if os.path.isdir(exec_dir+"/"+dirName):
		print("error:The output directory"+dirName+"is exit, please delete it !")
		sys.exit()
	os.mkdir(dirName)
	#Call the core program sim4
	CallSim4(args.longReadsFile,args.identity,length,args.thread,dirName)
	#carry on the second and the third data processing
	SecondDataProcess(dirName)
	#ThirdDataProcess(dirName)
	#subprocess.run('rm -rf '+dirName+'/GeneClusterTemp.txt',shell=True)

if __name__ == '__main__':
	Main()
